"""
Lumina å¿ƒèª - éŸ³é »æ··éŸ³æ¨¡çµ„ (Audio Mixer)
å°‡ç™‚ç™’èªéŸ³èˆ‡èƒŒæ™¯éŸ³æ¨‚æ··åˆè¼¸å‡º

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è¼‰å…¥èªéŸ³å’Œ BGM
2. è‡ªå‹•èª¿æ•´éŸ³é‡ï¼ˆèªéŸ³ä¿æŒï¼ŒBGM é™ä½ 20dBï¼‰
3. è‡ªå‹•è£åˆ‡/å¾ªç’° BGM å°é½ŠèªéŸ³é•·åº¦
4. æ·¡å…¥æ·¡å‡ºæ•ˆæœ
5. è¼¸å‡ºæ··éŸ³å¾Œçš„éŸ³é »
"""

import os
import random
from pathlib import Path
from io import BytesIO
from typing import Optional, Dict, Any, List

# å˜—è©¦å°å…¥ pydub
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub æœªå®‰è£ï¼Œæ··éŸ³åŠŸèƒ½ä¸å¯ç”¨")


# æƒ…ç·’åˆ° BGM é¢¨æ ¼çš„æ˜ å°„
EMOTION_TO_BGM_STYLE = {
    "ç„¦æ…®": "calm",
    "æ†¤æ€’": "gentle",
    "æ‚²å‚·": "ambient",
    "ææ‡¼": "soothing",
    "å›°æƒ‘": "meditative",
    "vulnerability": "ambient",
    "fear": "soothing",
    "anger": "gentle",
    "sadness": "ambient",
    "anxiety": "calm",
    "default": "healing"
}


class AudioMixer:
    """
    éŸ³é »æ··éŸ³å™¨ï¼šå°‡ç™‚ç™’èªéŸ³èˆ‡èƒŒæ™¯éŸ³æ¨‚æ··åˆ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        mixer = AudioMixer()
        mixed_audio = mixer.mix_voice_with_bgm(voice_bytes, emotion="calm")
    """
    
    def __init__(self, bgm_folder: Optional[Path] = None, auto_download: bool = True):
        """
        åˆå§‹åŒ–æ··éŸ³å™¨
        
        Args:
            bgm_folder: èƒŒæ™¯éŸ³æ¨‚æ–‡ä»¶å¤¾è·¯å¾‘ã€‚å¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨é è¨­çš„ assets/bgm/
            auto_download: æ˜¯å¦è‡ªå‹•ä¸‹è¼‰ BGMï¼ˆå¦‚æœæ–‡ä»¶å¤¾ç‚ºç©ºï¼‰
        """
        if not PYDUB_AVAILABLE:
            raise ImportError("pydub æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ pip install pydub")
        
        # è¨­å®š BGM æ–‡ä»¶å¤¾
        if bgm_folder:
            self.bgm_folder = Path(bgm_folder)
        else:
            self.bgm_folder = Path(__file__).parent.parent / "assets" / "bgm"
        
        # ç¢ºä¿æ–‡ä»¶å¤¾å­˜åœ¨
        self.bgm_folder.mkdir(parents=True, exist_ok=True)
        
        # æ··éŸ³åƒæ•¸ï¼ˆå°ˆæ¥­ç´šè¨­å®šï¼‰
        self.config = {
            "bgm_volume_reduction": -20,  # BGM é™ä½ 20dBï¼ˆè¼•æŸ”åŒ…è£¹æ„Ÿï¼‰
            "fade_in_duration": 3000,     # æ·¡å…¥ 3 ç§’
            "fade_out_duration": 5000,    # æ·¡å‡º 5 ç§’
            "crossfade_duration": 500,    # äº¤å‰æ·¡åŒ– 0.5 ç§’
        }
        
        # è‡ªå‹•ä¸‹è¼‰ BGMï¼ˆå¦‚æœéœ€è¦ï¼‰
        if auto_download and not self.get_available_bgm():
            self._ensure_bgm_available()
    
    def _ensure_bgm_available(self):
        """
        ç¢ºä¿æœ‰å¯ç”¨çš„ BGM
        
        å˜—è©¦é †åºï¼š
        1. èª¿ç”¨ BGMResourceManager ä¸‹è¼‰
        2. ç”Ÿæˆç¨‹åºåŒ–ç’°å¢ƒéŸ³
        """
        try:
            from conflict_analyzer.bgm_manager import BGMResourceManager
            
            manager = BGMResourceManager(self.bgm_folder)
            manager.download_sample_bgm()
            
        except Exception as e:
            print(f"âš ï¸ BGM è‡ªå‹•ä¸‹è¼‰å¤±æ•—: {e}")
    
    def get_available_bgm(self) -> List[Path]:
        """
        ç²å–å¯ç”¨çš„ BGM æ–‡ä»¶åˆ—è¡¨
        
        Returns:
            BGM æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        """
        supported_formats = [".mp3", ".wav", ".ogg", ".m4a", ".flac"]
        bgm_files = []
        
        if self.bgm_folder.exists():
            for f in self.bgm_folder.iterdir():
                if f.suffix.lower() in supported_formats:
                    bgm_files.append(f)
        
        return bgm_files
    
    def select_bgm(self, emotion: str = "default") -> Optional[Path]:
        """
        æ ¹æ“šæƒ…ç·’é¸æ“‡åˆé©çš„ BGM
        
        Args:
            emotion: æƒ…ç·’æ¨™ç±¤ï¼ˆå¦‚ calm, healing, anxietyï¼‰
            
        Returns:
            é¸ä¸­çš„ BGM æ–‡ä»¶è·¯å¾‘ï¼Œå¦‚æœæ²’æœ‰å¯ç”¨çš„ BGM å‰‡è¿”å› None
        """
        bgm_files = self.get_available_bgm()
        
        if not bgm_files:
            print("âš ï¸ BGM æ–‡ä»¶å¤¾ç‚ºç©ºï¼Œå°‡è¼¸å‡ºç´”èªéŸ³")
            return None
        
        # å˜—è©¦æ‰¾åˆ°åŒ¹é…æƒ…ç·’çš„ BGMï¼ˆæ–‡ä»¶ååŒ…å«æƒ…ç·’é—œéµè©ï¼‰
        style = EMOTION_TO_BGM_STYLE.get(emotion.lower(), "healing")
        
        for bgm in bgm_files:
            if style.lower() in bgm.stem.lower():
                print(f"ğŸ“[AudioMixer] é¸æ“‡åŒ¹é… BGM: {bgm.name}")
                return bgm
        
        # å¦‚æœæ²’æœ‰åŒ¹é…çš„ï¼Œéš¨æ©Ÿé¸æ“‡ä¸€å€‹
        selected = random.choice(bgm_files)
        print(f"ğŸ“[AudioMixer] éš¨æ©Ÿé¸æ“‡ BGM: {selected.name}")
        return selected
    
    def load_audio(self, audio_data: bytes, format: str = "wav") -> AudioSegment:
        """
        å¾ bytes è¼‰å…¥éŸ³é »
        
        Args:
            audio_data: éŸ³é »æ•¸æ“š bytes
            format: éŸ³é »æ ¼å¼
            
        Returns:
            AudioSegment å°è±¡
        """
        buffer = BytesIO(audio_data)
        return AudioSegment.from_file(buffer, format=format)
    
    def prepare_bgm(self, bgm: AudioSegment, target_duration: int) -> AudioSegment:
        """
        æº–å‚™ BGMï¼šèª¿æ•´é•·åº¦ä»¥åŒ¹é…èªéŸ³
        
        Args:
            bgm: èƒŒæ™¯éŸ³æ¨‚ AudioSegment
            target_duration: ç›®æ¨™æ™‚é•·ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            èª¿æ•´å¾Œçš„ BGM
        """
        bgm_duration = len(bgm)
        
        if bgm_duration >= target_duration:
            # BGM å¤ªé•·ï¼Œè£åˆ‡
            result = bgm[:target_duration]
            print(f"   ğŸ“ BGM è£åˆ‡è‡³ {target_duration/1000:.1f} ç§’")
        else:
            # BGM å¤ªçŸ­ï¼Œå¾ªç’°æ‹¼æ¥
            loops_needed = (target_duration // bgm_duration) + 1
            result = bgm * loops_needed
            result = result[:target_duration]
            print(f"   ğŸ” BGM å¾ªç’° {loops_needed} æ¬¡ä¸¦è£åˆ‡è‡³ {target_duration/1000:.1f} ç§’")
        
        return result
    
    def apply_effects(self, audio: AudioSegment) -> AudioSegment:
        """
        æ‡‰ç”¨æ·¡å…¥æ·¡å‡ºæ•ˆæœ
        
        Args:
            audio: åŸå§‹éŸ³é »
            
        Returns:
            è™•ç†å¾Œçš„éŸ³é »
        """
        fade_in = self.config["fade_in_duration"]
        fade_out = self.config["fade_out_duration"]
        
        # ç¢ºä¿æ·¡å…¥æ·¡å‡ºæ™‚é•·ä¸è¶…ééŸ³é »é•·åº¦çš„ä¸€åŠ
        audio_duration = len(audio)
        max_fade = audio_duration // 3
        
        fade_in = min(fade_in, max_fade)
        fade_out = min(fade_out, max_fade)
        
        return audio.fade_in(fade_in).fade_out(fade_out)
    
    def mix_voice_with_bgm(
        self,
        voice_bytes: bytes,
        emotion: str = "default",
        voice_format: str = "wav",
        bgm_path: Optional[Path] = None
    ) -> bytes:
        """
        å°‡èªéŸ³èˆ‡èƒŒæ™¯éŸ³æ¨‚æ··åˆ
        
        é€™æ˜¯ä¸»è¦çš„æ··éŸ³æ–¹æ³•ã€‚
        
        Args:
            voice_bytes: èªéŸ³éŸ³é »çš„ bytes
            emotion: æƒ…ç·’æ¨™ç±¤ï¼ˆç”¨æ–¼é¸æ“‡ BGM é¢¨æ ¼ï¼‰
            voice_format: èªéŸ³æ ¼å¼
            bgm_path: å¯é¸çš„æŒ‡å®š BGM è·¯å¾‘
            
        Returns:
            æ··åˆå¾Œçš„ WAV éŸ³é » bytes
        """
        print("\n" + "=" * 50)
        print("ğŸµ é–‹å§‹éŸ³é »æ··éŸ³ (Audio Mixing)")
        print("=" * 50)
        
        # 1. è¼‰å…¥èªéŸ³
        print("ğŸ“[AudioMixer] è¼‰å…¥èªéŸ³...")
        voice = self.load_audio(voice_bytes, voice_format)
        voice_duration = len(voice)
        print(f"   âœ… èªéŸ³æ™‚é•·: {voice_duration/1000:.1f} ç§’")
        
        # 2. é¸æ“‡ä¸¦è¼‰å…¥ BGM
        if bgm_path is None:
            bgm_path = self.select_bgm(emotion)
        
        if bgm_path is None:
            # æ²’æœ‰ BGMï¼Œåªè¿”å›è™•ç†å¾Œçš„èªéŸ³
            print("   âš ï¸ ç„¡å¯ç”¨ BGMï¼Œè¿”å›ç´”èªéŸ³")
            result = self.apply_effects(voice)
            output_buffer = BytesIO()
            result.export(output_buffer, format="wav")
            output_buffer.seek(0)
            return output_buffer.read()
        
        # 3. è¼‰å…¥ BGM
        print(f"ğŸ“[AudioMixer] è¼‰å…¥ BGM: {bgm_path.name}")
        bgm = AudioSegment.from_file(str(bgm_path))
        
        # 4. æº–å‚™ BGMï¼ˆèª¿æ•´é•·åº¦ï¼‰
        print("ğŸ“[AudioMixer] æº–å‚™ BGM...")
        # BGM éœ€è¦æ¯”èªéŸ³é•·ä¸€é»ï¼Œç‚ºäº†æ·¡å‡ºæ•ˆæœ
        total_duration = voice_duration + self.config["fade_out_duration"]
        bgm = self.prepare_bgm(bgm, total_duration)
        
        # 5. èª¿æ•´ BGM éŸ³é‡
        volume_reduction = self.config["bgm_volume_reduction"]
        bgm = bgm + volume_reduction  # pydub ä½¿ç”¨ + é‹ç®—ç¬¦èª¿æ•´ dB
        print(f"   ğŸ”Š BGM éŸ³é‡é™ä½ {abs(volume_reduction)}dB")
        
        # 6. æ··éŸ³ï¼ˆç–ŠåŠ ï¼‰
        print("ğŸ“[AudioMixer] åŸ·è¡Œæ··éŸ³...")
        # å…ˆå° BGM æ‡‰ç”¨æ·¡å…¥æ·¡å‡º
        bgm = self.apply_effects(bgm)
        
        # ç–ŠåŠ ï¼šèªéŸ³è¦†è“‹åœ¨ BGM ä¸Š
        # èªéŸ³å¾é ­é–‹å§‹ç–ŠåŠ 
        mixed = bgm.overlay(voice, position=0)
        
        # 7. è¼¸å‡º
        output_buffer = BytesIO()
        mixed.export(output_buffer, format="wav")
        output_buffer.seek(0)
        
        print("=" * 50)
        print(f"âœ… æ··éŸ³å®Œæˆï¼ç¸½æ™‚é•·: {len(mixed)/1000:.1f} ç§’")
        print("=" * 50 + "\n")
        
        return output_buffer.read()
    
    def mix_with_ducking(
        self,
        voice_bytes: bytes,
        emotion: str = "default",
        voice_format: str = "wav",
        duck_amount: int = -6
    ) -> bytes:
        """
        é€²éšæ··éŸ³ï¼šå¸¶æœ‰è‡ªå‹•é–ƒé¿ (Ducking) æ•ˆæœ
        
        ç•¶èªéŸ³å‡ºç¾æ™‚ï¼ŒBGM è‡ªå‹•é™ä½éŸ³é‡ï¼›èªéŸ³åœé “æ™‚ï¼ŒBGM ç¨å¾®å‡å›ã€‚
        é€™æ˜¯å°ˆæ¥­ç™‚ç™’éŸ³é »çš„æ¨™æº–åšæ³•ã€‚
        
        æ³¨æ„ï¼šé€™å€‹åŠŸèƒ½éœ€è¦æ›´è¤‡é›œçš„å¯¦ä½œï¼Œç›®å‰åƒ…ä½œç‚ºæ¥å£é ç•™ã€‚
        
        Args:
            voice_bytes: èªéŸ³éŸ³é »
            emotion: æƒ…ç·’æ¨™ç±¤
            voice_format: èªéŸ³æ ¼å¼
            duck_amount: Ducking æ™‚é¡å¤–é™ä½çš„ dBï¼ˆé è¨­ -6dBï¼‰
            
        Returns:
            æ··åˆå¾Œçš„éŸ³é » bytes
        """
        # TODO: å¯¦ä½œçœŸæ­£çš„ ducking é‚è¼¯
        # ç›®å‰å…ˆä½¿ç”¨åŸºç¤æ··éŸ³
        print("ğŸ“[AudioMixer] Ducking åŠŸèƒ½é–‹ç™¼ä¸­ï¼Œä½¿ç”¨æ¨™æº–æ··éŸ³")
        return self.mix_voice_with_bgm(voice_bytes, emotion, voice_format)
    
    def mix_voice_with_lyria(
        self,
        voice_bytes: bytes,
        emotion: str = "healing",
        voice_format: str = "wav"
    ) -> bytes:
        """
        ä½¿ç”¨ Lyria ç”ŸæˆåŸå‰µ BGM ä¸¦èˆ‡èªéŸ³æ··åˆ
        
        é€™æ˜¯æœ€æ¨è–¦çš„æ–¹æ³•ï¼šä½¿ç”¨ Google Lyria API æ ¹æ“šæƒ…ç·’
        å‹•æ…‹ç”ŸæˆåŸå‰µç™‚ç™’éŸ³æ¨‚ã€‚
        
        Args:
            voice_bytes: èªéŸ³éŸ³é »
            emotion: æƒ…ç·’æ¨™ç±¤
            voice_format: èªéŸ³æ ¼å¼
            
        Returns:
            æ··åˆå¾Œçš„éŸ³é » bytes
        """
        print("\n" + "=" * 50)
        print("ğŸ¼ ä½¿ç”¨ Lyria ç”ŸæˆåŸå‰µ BGM")
        print("=" * 50)
        
        try:
            from conflict_analyzer.lyria_music import LyriaMusicGenerator
            
            # è¼‰å…¥èªéŸ³è¨ˆç®—æ™‚é•·
            voice = self.load_audio(voice_bytes, voice_format)
            voice_duration_sec = len(voice) // 1000 + 10  # å¤š 10 ç§’ç¢ºä¿è¶³å¤ 
            
            print(f"ğŸ“[Lyria] èªéŸ³æ™‚é•·: {len(voice)/1000:.1f}sï¼Œç”Ÿæˆ {voice_duration_sec}s BGM")
            
            # ä½¿ç”¨ Lyria ç”Ÿæˆ BGM
            lyria = LyriaMusicGenerator()
            bgm_bytes = lyria.generate_bgm_sync(emotion, voice_duration_sec)
            
            # é™æ¡æ¨£åˆ° 24kHzï¼ˆèˆ‡èªéŸ³å°é½Šï¼‰
            bgm_24khz = lyria.resample_to_24khz(bgm_bytes)
            
            # è¼‰å…¥ä¸¦è™•ç† BGM
            bgm = AudioSegment.from_wav(BytesIO(bgm_24khz))
            
            # èª¿æ•´éŸ³é‡
            volume_reduction = self.config["bgm_volume_reduction"]
            bgm = bgm + volume_reduction
            print(f"   ğŸ”Š Lyria BGM éŸ³é‡é™ä½ {abs(volume_reduction)}dB")
            
            # è£åˆ‡åˆ°èªéŸ³é•·åº¦
            total_duration = len(voice) + self.config["fade_out_duration"]
            bgm = self.prepare_bgm(bgm, total_duration)
            
            # æ‡‰ç”¨æ·¡å…¥æ·¡å‡º
            bgm = self.apply_effects(bgm)
            
            # æ··éŸ³
            print("ğŸ“[AudioMixer] åŸ·è¡Œæ··éŸ³...")
            mixed = bgm.overlay(voice, position=0)
            
            # è¼¸å‡º
            output_buffer = BytesIO()
            mixed.export(output_buffer, format="wav")
            output_buffer.seek(0)
            
            print("=" * 50)
            print(f"âœ… Lyria æ··éŸ³å®Œæˆï¼ç¸½æ™‚é•·: {len(mixed)/1000:.1f} ç§’")
            print("=" * 50 + "\n")
            
            return output_buffer.read()
            
        except Exception as e:
            print(f"\nâš ï¸ Lyria ç”Ÿæˆå¤±æ•—: {e}")
            print("   éŒ¯èª¤é¡å‹:", type(e).__name__)
            
            # å˜—è©¦ Replicate MusicGen ä½œç‚ºç¬¬äºŒå‚™ç”¨
            print("   å˜—è©¦ Replicate MusicGen å‚™ç”¨æ–¹æ¡ˆ...")
            try:
                from conflict_analyzer.replicate_music import ReplicateMusicGenerator, is_replicate_available
                
                if is_replicate_available():
                    replicate_gen = ReplicateMusicGenerator()
                    
                    # è¨ˆç®—éœ€è¦çš„æ™‚é•·
                    voice = self.load_audio(voice_bytes, voice_format)
                    voice_duration_sec = len(voice) // 1000 + 10
                    
                    # ä½¿ç”¨ Replicate ç”Ÿæˆä¸¦å¾ªç’°
                    bgm_bytes = replicate_gen.generate_and_loop(emotion, voice_duration_sec)
                    
                    # è¼‰å…¥ä¸¦è™•ç† BGM
                    bgm = AudioSegment.from_wav(BytesIO(bgm_bytes))
                    
                    # èª¿æ•´éŸ³é‡
                    volume_reduction = self.config["bgm_volume_reduction"]
                    bgm = bgm + volume_reduction
                    print(f"   ğŸ”Š Replicate BGM éŸ³é‡é™ä½ {abs(volume_reduction)}dB")
                    
                    # è£åˆ‡åˆ°èªéŸ³é•·åº¦
                    total_duration = len(voice) + self.config["fade_out_duration"]
                    bgm = self.prepare_bgm(bgm, total_duration)
                    
                    # æ‡‰ç”¨æ·¡å…¥æ·¡å‡º
                    bgm = self.apply_effects(bgm)
                    
                    # æ··éŸ³
                    print("ğŸ“[AudioMixer] åŸ·è¡Œ Replicate BGM æ··éŸ³...")
                    mixed = bgm.overlay(voice, position=0)
                    
                    # è¼¸å‡º
                    output_buffer = BytesIO()
                    mixed.export(output_buffer, format="wav")
                    output_buffer.seek(0)
                    
                    print("=" * 50)
                    print(f"âœ… Replicate æ··éŸ³å®Œæˆï¼ç¸½æ™‚é•·: {len(mixed)/1000:.1f} ç§’")
                    print("=" * 50 + "\n")
                    
                    return output_buffer.read()
                else:
                    print("   âš ï¸ REPLICATE_API_TOKEN æœªè¨­å®šï¼Œè·³é Replicate")
                    
            except ImportError:
                print("   âš ï¸ Replicate æ¨¡çµ„æœªæ‰¾åˆ°")
            except Exception as replicate_error:
                print(f"   âš ï¸ Replicate ä¹Ÿå¤±æ•—äº†: {replicate_error}")
            
            # é™ç´šä½¿ç”¨æœ¬åœ° BGM
            print("   é™ç´šä½¿ç”¨æœ¬åœ° BGM...")
            try:
                result = self.mix_voice_with_bgm(voice_bytes, emotion, voice_format)
                return result
            except Exception as fallback_error:
                print(f"\nğŸš¨ [AudioMixer] å®Œå…¨å¤±æ•—ï¼ç„¡æ³•é€²è¡Œæ··éŸ³")
                print(f"   Lyria å¤±æ•—åŸå› : {e}")
                print(f"   æœ¬åœ° BGM å¤±æ•—åŸå› : {fallback_error}")
                print(f"   ğŸ“ è¨ºæ–·å»ºè­°ï¼š")
                print(f"      1. è¨­å®š REPLICATE_API_TOKEN ä½¿ç”¨ Replicate å‚™ç”¨æ–¹æ¡ˆ")
                print(f"      2. æª¢æŸ¥ GEMINI_API_KEY æ˜¯å¦æœ‰ Lyria æ¬Šé™")
                print(f"      3. æª¢æŸ¥ assets/bgm/ è³‡æ–™å¤¾æ˜¯å¦æœ‰ MP3/WAV æª”æ¡ˆ")
                print(f"      4. ç¢ºèª FFmpeg å·²æ­£ç¢ºå®‰è£")
                print("   å°‡è¿”å›ç´”èªéŸ³ï¼ˆç„¡èƒŒæ™¯éŸ³æ¨‚ï¼‰")
                return voice_bytes


# ä¾¿æ·å‡½æ•¸
def mix_audio(
    voice_bytes: bytes,
    emotion: str = "default",
    bgm_folder: Optional[Path] = None,
    use_lyria: bool = True
) -> bytes:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå°‡èªéŸ³èˆ‡ BGM æ··åˆ
    
    Args:
        voice_bytes: èªéŸ³ bytes
        emotion: æƒ…ç·’æ¨™ç±¤
        bgm_folder: BGM æ–‡ä»¶å¤¾è·¯å¾‘
        use_lyria: æ˜¯å¦ä½¿ç”¨ Lyria ç”Ÿæˆ BGMï¼ˆé è¨­ Trueï¼‰
        
    Returns:
        æ··åˆå¾Œçš„éŸ³é » bytes
    """
    mixer = AudioMixer(bgm_folder, auto_download=not use_lyria)
    
    if use_lyria:
        return mixer.mix_voice_with_lyria(voice_bytes, emotion)
    else:
        return mixer.mix_voice_with_bgm(voice_bytes, emotion)


def mix_audio_with_lyria(voice_bytes: bytes, emotion: str = "healing") -> bytes:
    """
    ä¾¿æ·å‡½æ•¸ï¼šä½¿ç”¨ Lyria ç”ŸæˆåŸå‰µ BGM ä¸¦æ··åˆ
    
    Args:
        voice_bytes: èªéŸ³ bytes
        emotion: æƒ…ç·’æ¨™ç±¤
        
    Returns:
        æ··åˆå¾Œçš„éŸ³é » bytes
    """
    mixer = AudioMixer(auto_download=False)
    return mixer.mix_voice_with_lyria(voice_bytes, emotion)
