"""
Lumina å¿ƒèª - æ ¸å¿ƒåˆ†ææ¨¡çµ„
ä¸€éšï¼šè¡çªæ¼”åŒ–è¿½è¹¤å™¨
äºŒéšï¼šæ·±å±¤æº¯æºèˆ‡æ¥ç´æ©‹æ¨‘
ä¸‰éšï¼šå€‹äººæˆé•·è¡Œå‹•æ–¹æ¡ˆ
"""

import os
import json
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
from dataclasses import dataclass

from google import genai
from google.genai import types

from .schemas import (
    ConflictAnalysisResult, Stage1Result, Stage2Result, Stage3Result,
    FullAnalysisResult, AnalysisError
)
from .prompts import (
    DEFAULT_STAGE1_PROMPT, DEFAULT_STAGE2_PROMPT, DEFAULT_STAGE3_PROMPT,
    get_analysis_prompt, get_stage2_prompt, get_stage3_prompt,
    SYSTEM_INSTRUCTION, DEFAULT_SYSTEM_PROMPT
)
from .audio_processor import AudioProcessor, AudioInfo


@dataclass
class AnalysisConfig:
    """åˆ†æé…ç½®"""
    model: str = "gemini-3-flash-preview"
    temperature: float = 0.7
    max_output_tokens: int = 8192
    include_reasoning: bool = True


class ConflictAnalyzerError(Exception):
    """è¡çªåˆ†æå™¨éŒ¯èª¤"""
    pass


class ConflictAnalyzer:
    """
    è¡çªåˆ†æå™¨
    æ”¯æ´ä¸‰éšåˆ†æï¼š
    - ä¸€éšï¼šè¡çªæ¼”åŒ–è¿½è¹¤
    - äºŒéšï¼šæ·±å±¤æº¯æºèˆ‡æ¥ç´æ©‹æ¨‘
    - ä¸‰éšï¼šå€‹äººæˆé•·è¡Œå‹•æ–¹æ¡ˆ
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        config: Optional[AnalysisConfig] = None
    ):
        self.api_key = api_key or os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
        if not self.api_key:
            raise ConflictAnalyzerError("âŒ æœªæ‰¾åˆ° API Key")
        
        self.config = config or AnalysisConfig()
        self.client = genai.Client(api_key=self.api_key)
        self.audio_processor = AudioProcessor()
        
        print(f"ğŸ“[ConflictAnalyzer] åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.config.model}")
    
    def _upload_audio(self, file_path: str) -> Any:
        """ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ"""
        path = Path(file_path)
        mime_type = self.audio_processor.get_mime_type(file_path)
        
        print(f"ğŸ“[ConflictAnalyzer] ä¸Šå‚³éŸ³è¨Š: {path.name}")
        
        try:
            uploaded_file = self.client.files.upload(file=str(path))
            print(f"ğŸ“[ConflictAnalyzer] ä¸Šå‚³æˆåŠŸ: {uploaded_file.name}")
            return uploaded_file
        except Exception as e:
            raise ConflictAnalyzerError(f"âŒ éŸ³è¨Šä¸Šå‚³å¤±æ•—: {e}")
    
    def _fix_truncated_json(self, raw_text: str) -> str:
        """
        å˜—è©¦ä¿®å¾©è¢«æˆªæ–·çš„ JSON å­—ç¬¦ä¸²
        
        å¸¸è¦‹æƒ…æ³ï¼š
        1. æœ«å°¾ç¼ºå°‘ } æˆ– ]
        2. å­—ç¬¦ä¸²æœªæ­£ç¢ºé–‰åˆ
        3. å¤šé¤˜çš„é€—è™Ÿ
        """
        import re
        
        text = raw_text.strip()
        
        # çµ±è¨ˆé–‹é–‰æ‹¬è™Ÿ
        open_braces = text.count('{')
        close_braces = text.count('}')
        open_brackets = text.count('[')
        close_brackets = text.count(']')
        
        # å˜—è©¦ä¿®å¾©æœªé–‰åˆçš„å­—ç¬¦ä¸²
        # æ‰¾æœ€å¾Œä¸€å€‹æœªé–‰åˆçš„å¼•è™Ÿ
        in_string = False
        escape_next = False
        for i, c in enumerate(text):
            if escape_next:
                escape_next = False
                continue
            if c == '\\':
                escape_next = True
                continue
            if c == '"':
                in_string = not in_string
        
        # å¦‚æœåœ¨å­—ç¬¦ä¸²ä¸­çµæŸï¼Œæ·»åŠ é–‰åˆå¼•è™Ÿ
        if in_string:
            text += '"'
        
        # ç§»é™¤æœ«å°¾å¤šé¤˜çš„é€—è™Ÿ
        text = re.sub(r',\s*$', '', text)
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)
        
        # è£œå……ç¼ºå¤±çš„æ‹¬è™Ÿ
        missing_braces = open_braces - text.count('}')
        missing_brackets = open_brackets - text.count(']')
        
        text += ']' * missing_brackets
        text += '}' * missing_braces
        
        print(f"âš ï¸ [JSONä¿®å¾©] è£œå……äº† {missing_braces} å€‹ '}}' å’Œ {missing_brackets} å€‹ ']'")
        
        return text
    
    
    def analyze_stage1(
        self,
        audio_path: str,
        additional_context: str = "",
        system_prompt: Optional[str] = None,
        verbose: bool = True
    ) -> Stage1Result:
        """
        ã€ä¸€éšåˆ†æã€‘è¡çªæ¼”åŒ–è¿½è¹¤
        
        åˆ†æéŸ³è¨Šä¸­çš„è¡çªæ¼”åŒ–éç¨‹ï¼Œè¼¸å‡ºè¡Œç‚ºå±¤é¢çš„è§€å¯Ÿã€‚
        """
        active_prompt = system_prompt if system_prompt else DEFAULT_STAGE1_PROMPT
        
        # é©—è­‰éŸ³è¨Š
        is_valid, message = self.audio_processor.validate_audio_file(audio_path)
        if not is_valid:
            raise ConflictAnalyzerError(message)
        
        if verbose:
            print(message)
        
        # ç²å–éŸ³è¨Šè³‡è¨Š
        audio_info = self.audio_processor.get_audio_info(audio_path)
        if verbose:
            print(f"ğŸ“[ä¸€éšåˆ†æ] éŸ³è¨Šæ™‚é•·: {self.audio_processor.format_duration(audio_info.duration_seconds)}")
        
        # ä¸Šå‚³éŸ³è¨Š
        uploaded_file = self._upload_audio(audio_path)
        
        # æ§‹å»ºæç¤ºè©
        analysis_prompt = get_analysis_prompt(additional_context)
        
        if verbose:
            print(f"ğŸ“[ä¸€éšåˆ†æ] é–‹å§‹åˆ†æï¼šè¡çªæ¼”åŒ–è¿½è¹¤...")
        
        try:
            response = self.client.models.generate_content(
                model=self.config.model,
                contents=[uploaded_file, analysis_prompt],
                config=types.GenerateContentConfig(
                    system_instruction=active_prompt,
                    temperature=self.config.temperature,
                    max_output_tokens=self.config.max_output_tokens,
                    response_mime_type="application/json",
                    response_schema=Stage1Result
                )
            )
        except Exception as e:
            raise ConflictAnalyzerError(f"âŒ ä¸€éšåˆ†æ API èª¿ç”¨å¤±æ•—: {e}")
        
        if verbose:
            print(f"ğŸ“[ä¸€éšåˆ†æ] âœ… å®Œæˆ")
        
        try:
            raw_text = response.text
            # å˜—è©¦ç›´æ¥è§£æ
            try:
                result_data = json.loads(raw_text)
            except json.JSONDecodeError as parse_err:
                # å˜—è©¦ä¿®å¾©æˆªæ–·çš„ JSON
                print(f"âš ï¸ [ä¸€éšåˆ†æ] JSON è§£æå¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©: {parse_err}")
                fixed_text = self._fix_truncated_json(raw_text)
                result_data = json.loads(fixed_text)
            
            result = Stage1Result.model_validate(result_data)
            return result
        except Exception as e:
            # æ‰“å°åŸå§‹éŸ¿æ‡‰ä»¥ä¾¿èª¿è©¦
            print(f"âŒ [ä¸€éšåˆ†æ] åŸå§‹éŸ¿æ‡‰ï¼ˆå‰ 500 å­—å…ƒï¼‰: {response.text[:500]}...")
            raise ConflictAnalyzerError(f"âŒ ä¸€éšçµæœè§£æå¤±æ•—: {e}")
    
    def analyze_stage2(
        self,
        stage1_result: dict,
        additional_context: str = "",
        system_prompt: Optional[str] = None,
        verbose: bool = True
    ) -> Stage2Result:
        """
        ã€äºŒéšåˆ†æã€‘æ·±å±¤æº¯æºèˆ‡æ¥ç´æ©‹æ¨‘
        
        åŸºæ–¼ä¸€éšåˆ†æçµæœï¼Œæ¢ç´¢æ·±å±¤å¿ƒç†å‹•åŠ›ã€‚
        ä¸Šä¸‹æ–‡ï¼šä¸€éšçµæœ
        """
        active_prompt = system_prompt if system_prompt else DEFAULT_STAGE2_PROMPT
        
        if verbose:
            print(f"ğŸ“[äºŒéšåˆ†æ] é–‹å§‹åˆ†æï¼šæ·±å±¤æº¯æºèˆ‡æ¥ç´æ©‹æ¨‘...")
        
        # æ§‹å»ºäºŒéšæç¤ºè©ï¼ˆä»¥ä¸€éšçµæœç‚ºä¸Šä¸‹æ–‡ï¼‰
        stage2_prompt = get_stage2_prompt(stage1_result, additional_context)
        
        try:
            response = self.client.models.generate_content(
                model=self.config.model,
                contents=[stage2_prompt],
                config=types.GenerateContentConfig(
                    system_instruction=active_prompt,
                    temperature=self.config.temperature,
                    max_output_tokens=self.config.max_output_tokens,
                    response_mime_type="application/json",
                    response_schema=Stage2Result
                )
            )
        except Exception as e:
            raise ConflictAnalyzerError(f"âŒ äºŒéšåˆ†æ API èª¿ç”¨å¤±æ•—: {e}")
        
        if verbose:
            print(f"ğŸ“[äºŒéšåˆ†æ] âœ… å®Œæˆ")
        
        try:
            raw_text = response.text
            # å˜—è©¦ç›´æ¥è§£æ
            try:
                result_data = json.loads(raw_text)
            except json.JSONDecodeError as parse_err:
                # å˜—è©¦ä¿®å¾©æˆªæ–·çš„ JSON
                print(f"âš ï¸ [äºŒéšåˆ†æ] JSON è§£æå¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©: {parse_err}")
                fixed_text = self._fix_truncated_json(raw_text)
                result_data = json.loads(fixed_text)
            
            result = Stage2Result.model_validate(result_data)
            return result
        except Exception as e:
            # æ‰“å°åŸå§‹éŸ¿æ‡‰ä»¥ä¾¿èª¿è©¦
            print(f"âŒ [äºŒéšåˆ†æ] åŸå§‹éŸ¿æ‡‰ï¼ˆå‰ 500 å­—å…ƒï¼‰: {response.text[:500]}...")
            raise ConflictAnalyzerError(f"âŒ äºŒéšçµæœè§£æå¤±æ•—: {e}")
    
    def analyze_stage3(
        self,
        stage1_result: dict,
        stage2_result: dict,
        additional_context: str = "",
        system_prompt: Optional[str] = None,
        verbose: bool = True
    ) -> Stage3Result:
        """
        ã€ä¸‰éšåˆ†æã€‘å€‹äººæˆé•·è¡Œå‹•æ–¹æ¡ˆ
        
        åŸºæ–¼ä¸€éšå’ŒäºŒéšåˆ†æçµæœï¼Œæä¾›ã€Œæˆ‘èƒ½åšä»€éº¼ã€çš„è¡Œå‹•æ–¹æ¡ˆã€‚
        ä¸Šä¸‹æ–‡ï¼šä¸€éšçµæœ + äºŒéšçµæœ
        """
        active_prompt = system_prompt if system_prompt else DEFAULT_STAGE3_PROMPT
        
        if verbose:
            print(f"ğŸ“[ä¸‰éšåˆ†æ] é–‹å§‹åˆ†æï¼šå€‹äººæˆé•·è¡Œå‹•æ–¹æ¡ˆ...")
        
        # æ§‹å»ºä¸‰éšæç¤ºè©ï¼ˆä»¥ä¸€éšï¼‹äºŒéšçµæœç‚ºä¸Šä¸‹æ–‡ï¼‰
        stage3_prompt = get_stage3_prompt(stage1_result, stage2_result, additional_context)
        
        try:
            response = self.client.models.generate_content(
                model=self.config.model,
                contents=[stage3_prompt],
                config=types.GenerateContentConfig(
                    system_instruction=active_prompt,
                    temperature=self.config.temperature,
                    max_output_tokens=self.config.max_output_tokens,
                    response_mime_type="application/json",
                    response_schema=Stage3Result
                )
            )
        except Exception as e:
            raise ConflictAnalyzerError(f"âŒ ä¸‰éšåˆ†æ API èª¿ç”¨å¤±æ•—: {e}")
        
        if verbose:
            print(f"ğŸ“[ä¸‰éšåˆ†æ] âœ… å®Œæˆ")
        
        try:
            raw_text = response.text
            # å˜—è©¦ç›´æ¥è§£æ
            try:
                result_data = json.loads(raw_text)
            except json.JSONDecodeError as parse_err:
                # å˜—è©¦ä¿®å¾©æˆªæ–·çš„ JSON
                print(f"âš ï¸ [ä¸‰éšåˆ†æ] JSON è§£æå¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©: {parse_err}")
                fixed_text = self._fix_truncated_json(raw_text)
                result_data = json.loads(fixed_text)
            
            result = Stage3Result.model_validate(result_data)
            return result
        except Exception as e:
            # æ‰“å°åŸå§‹éŸ¿æ‡‰ä»¥ä¾¿èª¿è©¦
            print(f"âŒ [ä¸‰éšåˆ†æ] åŸå§‹éŸ¿æ‡‰ï¼ˆå‰ 500 å­—å…ƒï¼‰: {response.text[:500]}...")
            raise ConflictAnalyzerError(f"âŒ ä¸‰éšçµæœè§£æå¤±æ•—: {e}")
    
    def full_analysis(
        self,
        audio_path: str,
        additional_context: str = "",
        stage1_prompt: Optional[str] = None,
        stage2_prompt: Optional[str] = None,
        stage3_prompt: Optional[str] = None,
        verbose: bool = True
    ) -> Tuple[Stage1Result, Stage2Result, Stage3Result]:
        """
        å®Œæ•´ä¸‰éšæ®µåˆ†æï¼šè‡ªå‹•ä¸²æ¥ï¼Œä¸Šä¸‹æ–‡é€å±¤å‚³é
        
        æµç¨‹ï¼š
        1. ä¸€éšåˆ†æï¼ˆéŸ³è¨Š â†’ è¡çªæ¼”åŒ–åœ°åœ–ï¼‰
        2. äºŒéšåˆ†æï¼ˆä¸€éšçµæœ â†’ æ·±å±¤æº¯æºï¼‰
        3. ä¸‰éšåˆ†æï¼ˆä¸€éš+äºŒéšçµæœ â†’ å€‹äººæˆé•·æ–¹æ¡ˆï¼‰
        
        Returns:
            (ä¸€éšçµæœ, äºŒéšçµæœ, ä¸‰éšçµæœ)
        """
        # ==================== ä¸€éšåˆ†æ ====================
        if verbose:
            print("\n" + "=" * 60)
            print("ğŸ”¬ ã€ç¬¬ä¸€éšæ®µã€‘è¡çªæ¼”åŒ–è¿½è¹¤")
            print("    åˆ†æéŸ³è¨Šä¸­çš„è¡Œç‚ºæ¨¡å¼èˆ‡äº’å‹•è»Œè·¡")
            print("=" * 60)
        
        stage1_result = self.analyze_stage1(
            audio_path=audio_path,
            additional_context=additional_context,
            system_prompt=stage1_prompt,
            verbose=verbose
        )
        
        # ==================== äºŒéšåˆ†æ ====================
        if verbose:
            print("\n" + "=" * 60)
            print("ğŸ’¡ ã€ç¬¬äºŒéšæ®µã€‘æ·±å±¤æº¯æºèˆ‡æ¥ç´æ©‹æ¨‘")
            print("    æ¢ç´¢è¡Œç‚ºèƒŒå¾Œçš„å¿ƒç†å‹•åŠ›èˆ‡å†°å±±ä¸‹æ–¹")
            print("    ğŸ“¥ ä¸Šä¸‹æ–‡å‚³éï¼šä¸€éšåˆ†æçµæœ")
            print("=" * 60)
        
        stage1_dict = stage1_result.model_dump()
        
        stage2_result = self.analyze_stage2(
            stage1_result=stage1_dict,
            additional_context=additional_context,
            system_prompt=stage2_prompt,
            verbose=verbose
        )
        
        # ==================== ä¸‰éšåˆ†æ ====================
        if verbose:
            print("\n" + "=" * 60)
            print("ğŸŒ± ã€ç¬¬ä¸‰éšæ®µã€‘å€‹äººæˆé•·è¡Œå‹•æ–¹æ¡ˆ")
            print("    èšç„¦ã€Œæˆ‘èƒ½åšä»€éº¼ã€çš„å…·é«”è¡Œå‹•")
            print("    ğŸ“¥ ä¸Šä¸‹æ–‡å‚³éï¼šä¸€éš + äºŒéšåˆ†æçµæœ")
            print("=" * 60)
        
        stage2_dict = stage2_result.model_dump()
        
        stage3_result = self.analyze_stage3(
            stage1_result=stage1_dict,
            stage2_result=stage2_dict,
            additional_context=additional_context,
            system_prompt=stage3_prompt,
            verbose=verbose
        )
        
        # ==================== å®Œæˆ ====================
        if verbose:
            print("\n" + "=" * 60)
            print("âœ… ä¸‰éšæ®µå®Œæ•´åˆ†æå®Œæˆ")
            print("=" * 60)
        
        return stage1_result, stage2_result, stage3_result
    
    # å‘å¾Œç›¸å®¹
    def analyze(
        self,
        audio_path: str,
        additional_context: str = "",
        system_prompt: Optional[str] = None,
        verbose: bool = True
    ) -> ConflictAnalysisResult:
        """å‘å¾Œç›¸å®¹çš„ä¸€éšåˆ†ææ–¹æ³•"""
        result = self.analyze_stage1(audio_path, additional_context, system_prompt, verbose)
        return ConflictAnalysisResult.model_validate(result.model_dump())
    
    def analyze_with_retry(
        self,
        audio_path: str,
        max_retries: int = 3,
        **kwargs
    ) -> ConflictAnalysisResult:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„ä¸€éšåˆ†æ"""
        import time
        
        last_error = None
        for attempt in range(max_retries):
            try:
                return self.analyze(audio_path, **kwargs)
            except ConflictAnalyzerError as e:
                last_error = e
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    print(f"âš ï¸ åˆ†æå¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries})ï¼Œ{wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
        
        raise last_error
    
    def get_audio_info(self, audio_path: str) -> AudioInfo:
        """ç²å–éŸ³è¨Šæª”æ¡ˆè³‡è¨Š"""
        return self.audio_processor.get_audio_info(audio_path)
