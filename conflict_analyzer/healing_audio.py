"""
è¡çªåŸºå›  - ç™‚è‚²éŸ³é »ç”Ÿæˆæ¨¡çµ„ v2.0
å¯¦ä½œã€Œåˆ†æ®µç”Ÿæˆèˆ‡è‡ªå‹•ä¸²æ¥ã€é‚è¼¯ï¼Œè§£æ±º TTS API è¼¸å‡ºé•·åº¦é™åˆ¶

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. script_splitter - æ ¹æ“š [PART_X] æ¨™ç±¤æ‹†åˆ†æ–‡ç¨¿
2. é †åºç”Ÿæˆæ¯å€‹ç‰‡æ®µçš„éŸ³é »
3. ä½¿ç”¨ pydub ç„¡ç¸«ç¸«åˆæ‰€æœ‰ç‰‡æ®µ
"""

import os
import re
import wave
import base64
from io import BytesIO
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from google import genai
from google.genai import types

# å˜—è©¦å°å…¥ pydubï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨ç´” WAV æ‹¼æ¥
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸ pydub æœªå®‰è£ï¼Œå°‡ä½¿ç”¨åŸºç¤ WAV æ‹¼æ¥")

# æ¨¡å‹å¸¸é‡
TTS_MODEL = "gemini-2.5-flash-preview-tts"  # TTS å°ˆç”¨æ¨¡å‹
TEXT_MODEL = "gemini-2.5-flash"  # ç”¨æ–¼ç”Ÿæˆæ–‡ç¨¿

# å¯ç”¨çš„è²éŸ³é¸é … (ä¸­æ–‡æ¨è–¦ä½¿ç”¨ Kore æˆ– Aoede)
VOICE_OPTIONS = {
    "warm_female": "Kore",      # æº«æš–å¥³è²
    "calm_female": "Aoede",     # å¹³éœå¥³è²
    "gentle_male": "Charon",    # æº«å’Œç”·è²
    "soothing_male": "Fenrir",  # èˆ’ç·©ç”·è²
}


def split_script_by_parts(script: str) -> List[Tuple[str, str]]:
    """
    æ ¹æ“š [PART_X] æ¨™ç±¤å°‡è…³æœ¬æ‹†åˆ†ç‚ºå¤šå€‹ç‰‡æ®µ
    
    Args:
        script: åŒ…å« [PART_1], [PART_2] ç­‰æ¨™ç±¤çš„å®Œæ•´è…³æœ¬
        
    Returns:
        List of tuples: [(part_name, content), ...]
    """
    # åŒ¹é… [PART_X] æ ¼å¼çš„æ¨™ç±¤
    pattern = r'\[PART_(\d+)\]'
    
    # æ‰¾åˆ°æ‰€æœ‰æ¨™ç±¤çš„ä½ç½®
    matches = list(re.finditer(pattern, script))
    
    if not matches:
        # å¦‚æœæ²’æœ‰æ¨™ç±¤ï¼Œè¿”å›æ•´å€‹è…³æœ¬ä½œç‚ºå–®ä¸€ç‰‡æ®µ
        print("âš ï¸ æœªæ‰¾åˆ° [PART_X] æ¨™ç±¤ï¼Œå°‡æ•´é«”ä½œç‚ºå–®ä¸€ç‰‡æ®µè™•ç†")
        return [("PART_1", script.strip())]
    
    parts = []
    for i, match in enumerate(matches):
        part_name = f"PART_{match.group(1)}"
        start = match.end()
        
        # çµæŸä½ç½®æ˜¯ä¸‹ä¸€å€‹æ¨™ç±¤çš„é–‹å§‹ï¼Œæˆ–è€…æ˜¯æ–‡æœ¬æœ«å°¾
        if i + 1 < len(matches):
            end = matches[i + 1].start()
        else:
            end = len(script)
        
        content = script[start:end].strip()
        if content:  # åªæ·»åŠ éç©ºå…§å®¹
            parts.append((part_name, content))
    
    print(f"ğŸ“[Script Splitter] æˆåŠŸæ‹†åˆ†ç‚º {len(parts)} å€‹ç‰‡æ®µ")
    for name, content in parts:
        print(f"   - {name}: {len(content)} å­—")
    
    return parts


class HealingAudioGenerator:
    """ç”Ÿæˆç™‚è‚²éŸ³é »çš„æ ¸å¿ƒé¡ï¼ˆæ”¯æ´åˆ†æ®µç”Ÿæˆèˆ‡ä¸²æ¥ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("éœ€è¦ GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        self.client = genai.Client(api_key=self.api_key)
    
    def generate_healing_script(
        self,
        stage1_result: Dict[str, Any],
        stage2_result: Dict[str, Any],
        stage3_result: Dict[str, Any],
        system_prompt: str,
        additional_context: str = ""
    ) -> str:
        """
        ç”Ÿæˆç™‚è‚²éŸ³é »æ–‡ç¨¿ï¼ˆå¸¶æœ‰ [PART_X] æ¨™ç±¤ï¼‰
        
        Returns:
            åŒ…å« [PART_1], [PART_2], ... æ¨™ç±¤çš„çµæ§‹åŒ–ç™‚è‚²è…³æœ¬
        """
        from conflict_analyzer.prompts import get_stage4_prompt
        
        print("ğŸ“[HealingAudioGenerator] æ­£åœ¨ç”Ÿæˆåˆ†æ®µç™‚è‚²æ–‡ç¨¿...")
        
        user_prompt = get_stage4_prompt(
            stage1_result, 
            stage2_result, 
            stage3_result,
            additional_context
        )
        
        try:
            response = self.client.models.generate_content(
                model=TEXT_MODEL,
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=0.8,
                )
            )
            
            script = response.text.strip()
            print(f"ğŸ“[HealingAudioGenerator] æ–‡ç¨¿ç”ŸæˆæˆåŠŸï¼ç¸½é•·åº¦: {len(script)} å­—")
            return script
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç™‚è‚²æ–‡ç¨¿éŒ¯èª¤: {e}")
            raise
    
    def text_to_speech_single(
        self,
        text: str,
        voice: str = "warm_female",
        part_name: str = ""
    ) -> bytes:
        """
        å°‡å–®ä¸€ç‰‡æ®µæ–‡å­—è½‰æ›ç‚ºèªéŸ³
        
        Args:
            text: è¦è½‰æ›çš„æ–‡å­—ï¼ˆæ‡‰æ§åˆ¶åœ¨ 200 å­—ä»¥å…§ï¼‰
            voice: è²éŸ³é¸é …
            part_name: ç‰‡æ®µåç¨±ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
            
        Returns:
            WAV éŸ³é »çš„ bytes
        """
        voice_name = VOICE_OPTIONS.get(voice, "Kore")
        
        print(f"   ğŸ™ï¸ æ­£åœ¨ç”Ÿæˆ {part_name}... ({len(text)} å­—)")
        
        try:
            response = self.client.models.generate_content(
                model=TTS_MODEL,
                contents=f"ç”¨æº«æŸ”ã€èˆ’ç·©ã€ç™‚ç™’çš„èªèª¿ç·©æ…¢æœ—è®€ä»¥ä¸‹æ–‡å­—ã€‚æ¯å€‹ã€Œ...ã€è™•è‡ªç„¶åœé “ã€‚èªé€Ÿæ”¾æ…¢ï¼Œè®“è½çœ¾èƒ½æ„Ÿå—åˆ°è¢«åŒ…è£¹çš„å®‰å…¨æ„Ÿï¼š\n\n{text}",
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice_name,
                            )
                        ),
                    ),
                )
            )
            
            # ç²å– PCM æ•¸æ“š
            pcm_data = response.candidates[0].content.parts[0].inline_data.data
            
            # è½‰æ›ç‚º WAV
            wav_data = self._pcm_to_wav(pcm_data)
            
            print(f"   âœ… {part_name} ç”Ÿæˆå®Œæˆ ({len(wav_data)} bytes)")
            return wav_data
            
        except Exception as e:
            print(f"   âŒ {part_name} ç”ŸæˆéŒ¯èª¤: {e}")
            raise
    
    def _pcm_to_wav(
        self, 
        pcm_data: bytes, 
        channels: int = 1, 
        rate: int = 24000, 
        sample_width: int = 2
    ) -> bytes:
        """å°‡ PCM æ•¸æ“šè½‰æ›ç‚º WAV æ ¼å¼"""
        buffer = BytesIO()
        with wave.open(buffer, "wb") as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(rate)
            wf.writeframes(pcm_data)
        
        buffer.seek(0)
        return buffer.read()
    
    def stitch_audio_clips(
        self, 
        audio_clips: List[bytes],
        silence_duration_ms: int = 800
    ) -> bytes:
        """
        å°‡å¤šå€‹éŸ³é »ç‰‡æ®µç„¡ç¸«ç¸«åˆ
        
        Args:
            audio_clips: WAV æ ¼å¼çš„éŸ³é »ç‰‡æ®µåˆ—è¡¨
            silence_duration_ms: ç‰‡æ®µä¹‹é–“çš„éœéŸ³æ™‚é•·ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            åˆä½µå¾Œçš„ WAV éŸ³é » bytes
        """
        print(f"ğŸ“[Audio Stitcher] æ­£åœ¨ç¸«åˆ {len(audio_clips)} å€‹éŸ³é »ç‰‡æ®µ...")
        
        if PYDUB_AVAILABLE:
            return self._stitch_with_pydub(audio_clips, silence_duration_ms)
        else:
            return self._stitch_basic_wav(audio_clips)
    
    def _stitch_with_pydub(
        self, 
        audio_clips: List[bytes],
        silence_duration_ms: int = 800
    ) -> bytes:
        """ä½¿ç”¨ pydub ç¸«åˆéŸ³é »ï¼ˆæ”¯æ´æ·¡å…¥æ·¡å‡ºï¼‰"""
        combined = AudioSegment.empty()
        
        for i, clip_data in enumerate(audio_clips):
            # å¾ bytes è¼‰å…¥éŸ³é »
            clip = AudioSegment.from_wav(BytesIO(clip_data))
            
            # æ·»åŠ æ·¡å…¥ï¼ˆé¦–ç‰‡æ®µï¼‰å’Œæ·¡å‡ºï¼ˆå°¾ç‰‡æ®µï¼‰æ•ˆæœ
            if i == 0:
                clip = clip.fade_in(500)  # 500ms æ·¡å…¥
            if i == len(audio_clips) - 1:
                clip = clip.fade_out(1000)  # 1000ms æ·¡å‡º
            
            # ç¸«åˆ
            if i > 0:
                # åœ¨ç‰‡æ®µä¹‹é–“æ·»åŠ çŸ­æš«éœéŸ³éæ¸¡
                silence = AudioSegment.silent(duration=silence_duration_ms)
                combined += silence
            
            combined += clip
        
        # å°å‡ºç‚º WAV
        output_buffer = BytesIO()
        combined.export(output_buffer, format="wav")
        output_buffer.seek(0)
        
        print(f"   âœ… éŸ³é »ç¸«åˆå®Œæˆï¼ç¸½æ™‚é•·: {len(combined) / 1000:.1f} ç§’")
        return output_buffer.read()
    
    def _stitch_basic_wav(self, audio_clips: List[bytes]) -> bytes:
        """åŸºç¤ WAV æ‹¼æ¥ï¼ˆä¸éœ€è¦ pydubï¼‰"""
        if not audio_clips:
            return b""
        
        # è®€å–ç¬¬ä¸€å€‹æª”æ¡ˆç²å–åƒæ•¸
        first_clip = BytesIO(audio_clips[0])
        with wave.open(first_clip, 'rb') as wf:
            params = wf.getparams()
            sample_rate = wf.getframerate()
            channels = wf.getnchannels()
            sample_width = wf.getsampwidth()
        
        # åˆä½µæ‰€æœ‰ PCM æ•¸æ“š
        all_frames = b""
        for clip_data in audio_clips:
            clip_buffer = BytesIO(clip_data)
            with wave.open(clip_buffer, 'rb') as wf:
                frames = wf.readframes(wf.getnframes())
                all_frames += frames
                # æ·»åŠ  0.5 ç§’éœéŸ³
                silence_frames = b'\x00' * int(sample_rate * channels * sample_width * 0.5)
                all_frames += silence_frames
        
        # å¯«å…¥æ–°çš„ WAV
        output_buffer = BytesIO()
        with wave.open(output_buffer, 'wb') as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(sample_rate)
            wf.writeframes(all_frames)
        
        output_buffer.seek(0)
        print(f"   âœ… åŸºç¤ WAV æ‹¼æ¥å®Œæˆ")
        return output_buffer.read()
    
    def generate_healing_audio(
        self,
        stage1_result: Dict[str, Any],
        stage2_result: Dict[str, Any],
        stage3_result: Dict[str, Any],
        system_prompt: str,
        voice: str = "warm_female",
        output_dir: Optional[Path] = None,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        å®Œæ•´æµç¨‹ï¼šç”Ÿæˆåˆ†æ®µç™‚è‚²æ–‡ç¨¿ä¸¦ä¸²æ¥ç‚ºå®Œæ•´éŸ³é »
        
        æµç¨‹ï¼š
        1. ç”Ÿæˆå¸¶æœ‰ [PART_X] æ¨™ç±¤çš„æ–‡ç¨¿
        2. æ‹†åˆ†æ–‡ç¨¿ç‚ºå¤šå€‹ç‰‡æ®µ
        3. é †åºç”Ÿæˆæ¯å€‹ç‰‡æ®µçš„éŸ³é »
        4. ä½¿ç”¨ pydub ç¸«åˆæ‰€æœ‰ç‰‡æ®µ
        
        Args:
            stage1_result: ä¸€éšåˆ†æçµæœ
            stage2_result: äºŒéšåˆ†æçµæœ
            stage3_result: ä¸‰éšåˆ†æçµæœ
            system_prompt: ç¬¬å››éš System Prompt
            voice: è²éŸ³é¸é …
            output_dir: å¯é¸çš„è¼¸å‡ºç›®éŒ„
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸ (current, total, message)
            
        Returns:
            {
                "script": str,           # å®Œæ•´æ–‡ç¨¿
                "audio_base64": str,     # Base64 ç·¨ç¢¼çš„ WAV éŸ³é »
                "duration_estimate": float,  # ä¼°ç®—æ™‚é•·ï¼ˆç§’ï¼‰
                "voice": str,            # ä½¿ç”¨çš„è²éŸ³
                "parts_count": int       # ç‰‡æ®µæ•¸é‡
            }
        """
        print("\n" + "=" * 50)
        print("ğŸµ é–‹å§‹ç”Ÿæˆç™‚è‚²éŸ³é »ï¼ˆåˆ†æ®µä¸²æ¥æ¨¡å¼ï¼‰")
        print("=" * 50)
        
        # 1. ç”Ÿæˆæ–‡ç¨¿
        if progress_callback:
            progress_callback(1, 4, "æ­£åœ¨ç”Ÿæˆç™‚è‚²æ–‡ç¨¿...")
        
        script = self.generate_healing_script(
            stage1_result,
            stage2_result,
            stage3_result,
            system_prompt
        )
        
        # 2. æ‹†åˆ†æ–‡ç¨¿
        if progress_callback:
            progress_callback(2, 4, "æ­£åœ¨æ‹†åˆ†æ–‡ç¨¿ç‰‡æ®µ...")
        
        parts = split_script_by_parts(script)
        
        # 3. é †åºç”Ÿæˆæ¯å€‹ç‰‡æ®µçš„éŸ³é »
        if progress_callback:
            progress_callback(3, 4, f"æ­£åœ¨ç”Ÿæˆ {len(parts)} å€‹éŸ³é »ç‰‡æ®µ...")
        
        print(f"\nğŸ“[Sequential TTS] é–‹å§‹é †åºç”Ÿæˆ {len(parts)} å€‹éŸ³é »ç‰‡æ®µ...")
        audio_clips = []
        
        for i, (part_name, content) in enumerate(parts, 1):
            try:
                audio_data = self.text_to_speech_single(content, voice, part_name)
                audio_clips.append(audio_data)
            except Exception as e:
                print(f"   âš ï¸ {part_name} ç”Ÿæˆå¤±æ•—ï¼Œè·³é: {e}")
                continue
        
        if not audio_clips:
            raise Exception("æ‰€æœ‰éŸ³é »ç‰‡æ®µç”Ÿæˆå¤±æ•—")
        
        # 4. ç¸«åˆéŸ³é »
        if progress_callback:
            progress_callback(4, 4, "æ­£åœ¨ç·¨ç¹”æ‚¨çš„å°ˆå±¬ç™‚ç™’èƒ½é‡...")
        
        final_audio = self.stitch_audio_clips(audio_clips)
        
        # å„²å­˜ï¼ˆå¦‚æœæŒ‡å®šäº†ç›®éŒ„ï¼‰
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / "healing_audio.wav"
            with open(output_path, "wb") as f:
                f.write(final_audio)
            print(f"ğŸ’¾ å·²å„²å­˜: {output_path}")
        
        print("\n" + "=" * 50)
        print("âœ… ç™‚è‚²éŸ³é »ç”Ÿæˆå®Œæˆï¼")
        print(f"   - ç‰‡æ®µæ•¸é‡: {len(audio_clips)}")
        print(f"   - ç¸½é•·åº¦: {len(final_audio)} bytes")
        print("=" * 50 + "\n")
        
        return {
            "script": script,
            "audio_base64": base64.b64encode(final_audio).decode("utf-8"),
            "duration_estimate": len(script) * 0.12,  # ä¼°ç®—æ™‚é•·ï¼ˆç§’ï¼‰
            "voice": voice,
            "parts_count": len(audio_clips)
        }


# ä¾¿æ·å‡½æ•¸
def generate_healing_audio_from_analysis(
    stage1: Dict[str, Any],
    stage2: Dict[str, Any],
    stage3: Dict[str, Any],
    system_prompt: str,
    voice: str = "warm_female"
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå¾åˆ†æçµæœç”Ÿæˆç™‚è‚²éŸ³é »ï¼ˆè‡ªå‹•åˆ†æ®µä¸²æ¥ï¼‰
    
    Returns:
        {
            "script": str,           # å®Œæ•´æ–‡ç¨¿
            "audio_base64": str,     # Base64 ç·¨ç¢¼çš„ WAV éŸ³é »
            "duration_estimate": float,  # ä¼°ç®—æ™‚é•·
            "voice": str,            # ä½¿ç”¨çš„è²éŸ³
            "parts_count": int       # ç‰‡æ®µæ•¸é‡
        }
    """
    generator = HealingAudioGenerator()
    return generator.generate_healing_audio(
        stage1_result=stage1,
        stage2_result=stage2,
        stage3_result=stage3,
        system_prompt=system_prompt,
        voice=voice
    )
